{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c679f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 18:35:14.161028: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 18:35:14.221650: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 18:35:14.222753: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 18:35:18.537446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.04 s, sys: 2.23 s, total: 8.27 s\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from MicroLIA import training_set\n",
    "from MicroLIA import ensemble_model as models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def set_data(dataset_path, model_name, app_w = True):\n",
    "    path_test = [Path(dataset_path, folder) for folder in os.listdir(dataset_path) if \"test\" in folder][0]\n",
    "    path_train = [Path(dataset_path, folder) for folder in os.listdir(dataset_path) if \"train\" in folder][0] #Path(folders_path,f\"training_set-{folders_path[:-1]}\") # here we put directories with lightcurves associated to a class\n",
    "    folders = [name for name in os.listdir(path_test) if not '.txt' in name]\n",
    "    data_x, data_y = training_set.load_all(path_train, apply_weights=app_w)\n",
    "    \n",
    "    model_result = Path(\"Models_results\", model_name+\"-\"+ dataset_path)\n",
    "    os.mkdir(model_result)\n",
    "    generated_files = [\"all_features_.txt\", \"lightcurves__.fits\", \"MicroLIA_Training_Set.csv\"]\n",
    "    for file in generated_files:\n",
    "        os.rename(Path(\"..\", file), Path(model_result, file))\n",
    "    return data_x, data_y, path_train, path_test, folders\n",
    "\n",
    "def set_model(model_name,  data_x, data_y, path_train, path_test, folders):\n",
    "    '''Set and create the model\n",
    "    Get predictions in \"predictions.txt\" with the columns: class, max_prob [prob of each class] file'''\n",
    "    model = models.Classifier(data_x,data_y, clf = \"xgb\", optimize=False, impute=True, balance=True)\n",
    "    model.create()\n",
    "    predict_array = np.empty((0,3+len(folders)))\n",
    "    for i, folder in enumerate(folders):\n",
    "        print(f\"Folder: {folder}    {i+1}/{len(folders)}\")\n",
    "        for file in tqdm(os.listdir(Path(path_test,folder))):\n",
    "            data = np.loadtxt(Path(path_test,folder, file))\n",
    "            time, mag, magerr = data[:,0], data[:,1], data[:,2]\n",
    "            pred = model.predict(time, mag, magerr, convert=True, zp=27.5)\n",
    "            predict_array = np.append(predict_array, [[folder,pred[np.argmax(pred[:,1])][0],*pred[:,1],file]],axis=0)\n",
    "    head_folders = \" \".join(folders)\n",
    "    headers=f\"class max_prob {head_folders} lc_file\".split(\" \")\n",
    "    predict_df = pd.DataFrame(predict_array, columns=headers)\n",
    "    predict_df.to_csv('predictions.txt', index=False, sep=' ')\n",
    "    os.rename(\"../predictions.txt\", Path(model_result, file))\n",
    "#     np.savetxt(Path(model_result, \"predictions.txt\", predict_array, header= f\"class max_prob {\" \".join(folders)} lc_file\", fmt='%s')\n",
    "    return model, predict_df # class, max_prob [prob of each class] file\n",
    "\n",
    "def metrics(y_true, y_pred, model_name, dataset_path):\n",
    "    '''Plot confusion matrix on \"cf_matrix.png\"\n",
    "    Write the presicion, recall, accuracy and f1 score in \"score_metrics.txt\"'''\n",
    "    model_result = Path(\"Models_results\", model_name+\"-\"+ dataset_path.split(\"/\")[-1])\n",
    "    if model_name == \"xgb\":\n",
    "        XGB = {}\n",
    "        for i, folder in enumerate(sorted(folders)):\n",
    "            XGB[f\"{i}.0\"]=folder\n",
    "        y_pred = [XGB[str(y)] for y in y_pred]\n",
    "\n",
    "    Labels = [name.split(\"_\")[-1] for name in folders]\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_true, y_pred, labels=folders, normalize='true')\n",
    "    precision = round(precision_score(y_true, y_pred, average='macro'),3)\n",
    "    recall = round(recall_score(y_true, y_pred, average='macro'),3)\n",
    "    accuracy = round(accuracy_score(y_true, y_pred),3)\n",
    "    f1_score = round((2*precision*recall)/(presicion+recall),3)\n",
    "    print('Precision score [tp/(tp+fp)] = ', precision)\n",
    "    print('Recall score [tp/(tp+fn)] = ', recall)\n",
    "    print('Accuracy = ', accuracy)\n",
    "    print('F1_score [2*presicion*recall/(pres+recall)] = ', f1_score)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))  \n",
    "    fontsize=10\n",
    "    sns.set(font_scale=fontsize/10)\n",
    "    s = sns.heatmap(cf_matrix, annot=True, cmap='viridis', xticklabels=Labels, yticklabels=Labels, ax=ax)  # cmap='OrRd'\n",
    "    plt.xticks(rotation=90,fontsize=fontsize)\n",
    "    plt.yticks(rotation=0,fontsize=fontsize) \n",
    "    plt.ylabel('True target',fontsize=fontsize) \n",
    "    plt.xlabel('Prediction (max_prom)',fontsize=fontsize) \n",
    "    plt.title(f'{model_name} {dataset_path.split(\"/\")[0]}\\n{precision}/{recall}/{accuracy}/{f1_score}')\n",
    "    plt.savefig(Path(model_result, \"cf_matrix.png\"))\n",
    "    plt.close()\n",
    "    with open(Path(model_result,\"score_metrics.txt\"), \"w\") as f:\n",
    "        f.write(f'Precision score [tp/(tp+fp)] = {precision}\\n' )\n",
    "        f.write(f'Recall score [tp/(tp+fn)] = {recall}\\n' )\n",
    "        f.write(f'Accuracy = {accuracy}\\n' )\n",
    "        f.write(f'F1_score [2*presicion*recall/(pres+recall)] = {f1_score}\\n' )\n",
    "    return cf_matrix, precision, recall, accuracy, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8b22a",
   "metadata": {},
   "source": [
    "clf (str) – The machine learning classifier to optimize. Can either be ‘rf’ for Random Forest, ‘nn’ for Neural Network, or ‘xgb’ for Extreme Gradient Boosting. Defaults to ‘rf’.\n",
    "models_names = [\"xgb\", \"rf\", \"nn\", \"cnn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa827e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBAR ESTO: \n",
    "\n",
    "dataset_path =     # Path of the folder where are the folders of the test and of the train sets\n",
    "model_name =       # \"xgb\", \"nn\", \"rf\"\n",
    " \n",
    "data_x, data_y, path_train, path_test, folders = set_data(dataset_path, model_name, app_w = True)\n",
    "model, predict_df = set_model(model_name, data_x, data_y, path_train, path_test, folders)\n",
    "y_true = predict_df[\"class\"]\n",
    "y_pred = predict_df[\"max_prom\"]\n",
    "cf_matrix, precision, recall, accuracy, f1_score = metrics(y_true, y_pred, model_name, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8168ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "xgb\n",
      "Anibal_dataset\n",
      "Writing files to home directory...\n",
      "(7388, 148) 148\n",
      "Complete! Files saved in: /home/nowokaren/\n",
      "XGBoost classifier requires numerical class labels! Converting class labels as follows:\n",
      "________________________________\n",
      "ELASTICC_TRAIN_EB  ------------->     0\n",
      "ELASTICC_TRAIN_Mdwarf-flare  ------------->     1\n",
      "ELASTICC_TRAIN_RRL  ------------->     2\n",
      "ELASTICC_TRAIN_uLens-Single_PyLIMA  ------------->     3\n",
      "________________________________\n",
      "Returning base xgb model...\n",
      "Folder: ELASTICC_TRAIN_EB    1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [01:49<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: ELASTICC_TRAIN_RRL    2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [01:54<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: ELASTICC_TRAIN_Mdwarf-flare    3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [01:45<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: ELASTICC_TRAIN_uLens-Single_PyLIMA    4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [03:15<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELASTICC_TRAIN_EB ELASTICC_TRAIN_EB\n",
      "Precision score [tp/(tp+fp)] =  0.859\n",
      "Recall score [tp/(tp+fn)] =  0.834\n",
      "Accuracy =  0.834\n"
     ]
    }
   ],
   "source": [
    "# runs = [(\"xgb\", \"2305222212Y\")]\n",
    "# dataset_paths = [\"2305222212\"+ i for i in \"ugrizY\"]\n",
    "# models_names = [\"rf\", \"nn\"]\n",
    "# for model in models_names:\n",
    "#     for run in dataset_paths:\n",
    "#         runs.append((model, run))\n",
    "# models_names.append(\"xgb\")\n",
    "runs = [(\"xgb\", \"Anibal_dataset\")]\n",
    "# for model in models_names:\n",
    "#     runs.append((model, \"Anibal_dataset\"))\n",
    "# dataset_path= \"2305222212/2305222212r\"\n",
    "\n",
    "for run in runs:\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(run[0])\n",
    "    print(run[1])\n",
    "    run_model(*run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cd3c7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-karen_env)",
   "language": "python",
   "name": "conda-env-.conda-karen_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
